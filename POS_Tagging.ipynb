{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea47b9c-783b-4213-8747-e2b5fff07c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "#nltk.download('treebank')\n",
    "#nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9770f704-6484-4dc3-a4e3-58336492db6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to C:\\Users\\RAMPALLI\n",
      "[nltk_data]     VAMSI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\treebank.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('treebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4270fc59-dd0e-4547-bf19-8ab1c7dd315c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to C:\\Users\\RAMPALLI\n",
      "[nltk_data]     VAMSI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\universal_tagset.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3d970ba-fa5a-4e62-b0d2-da0aedee48d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import treebank\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e7d23bf-8191-43e5-9afb-eb91571311e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Treebank corpus and split into training and testing sets\n",
    "data = treebank.tagged_sents(tagset='universal')\n",
    "train_data = data[:3000]\n",
    "test_data = data[3000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0821f45-fc36-4250-92bf-849a99216dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3914"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d292974-86c7-475d-9a28-3a4d5fb9f23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mr.', 'NOUN'),\n",
       " ('Vinken', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('chairman', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('Elsevier', 'NOUN'),\n",
       " ('N.V.', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('the', 'DET'),\n",
       " ('Dutch', 'NOUN'),\n",
       " ('publishing', 'VERB'),\n",
       " ('group', 'NOUN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9972754-c68a-45ba-9a11-0c9bf9c9d944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hmm_parameters(train_data):\n",
    "    tag_counts = Counter()\n",
    "    word_tag_counts = defaultdict(Counter)\n",
    "    transition_counts = defaultdict(Counter)\n",
    "    tag_bigrams = Counter()\n",
    "\n",
    "    for sentence in train_data:\n",
    "        prev_tag = '<s>'\n",
    "        for word, tag in sentence:\n",
    "            tag_counts[tag] += 1\n",
    "            word_tag_counts[word][tag] += 1\n",
    "            transition_counts[prev_tag][tag] += 1\n",
    "            tag_bigrams[(prev_tag, tag)] += 1\n",
    "            prev_tag = tag\n",
    "        transition_counts[prev_tag]['</s>'] += 1\n",
    "        tag_bigrams[(prev_tag, '</s>')] += 1\n",
    "\n",
    "    tags = list(tag_counts.keys())\n",
    "    words = list(word_tag_counts.keys())\n",
    "    \n",
    "    # Compute initial probabilities with Laplace smoothing\n",
    "    initial_prob = {tag: (transition_counts['<s>'][tag] + 1) / (sum(transition_counts['<s>'].values()) + len(tags)) for tag in tags}\n",
    "    \n",
    "    # Compute transition probabilities with Laplace smoothing\n",
    "    transition_prob = {\n",
    "        tag: {t: (transition_counts[tag][t] + 1) / (tag_counts[tag] + len(tags) + 1) for t in tags + ['</s>']}\n",
    "        for tag in tags + ['<s>']\n",
    "    }\n",
    "    \n",
    "    # Compute emission probabilities with Laplace smoothing\n",
    "    emission_prob = {\n",
    "        tag: {word: (word_tag_counts[word][tag] + 1) / (tag_counts[tag] + len(words)) for word in words}\n",
    "        for tag in tags\n",
    "    }\n",
    "    \n",
    "    return tags, words, initial_prob, transition_prob, emission_prob\n",
    "\n",
    "tags, words, initial_prob, transition_prob, emission_prob = create_hmm_parameters(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71850dfb-3ec1-4666-bbe1-c7f4f1ae794c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(sentence, tags, initial_prob, transition_prob, emission_prob):\n",
    "    n = len(sentence)\n",
    "    m = len(tags)\n",
    "    viterbi = np.zeros((m, n))\n",
    "    backpointer = np.zeros((m, n), dtype=int)\n",
    "    \n",
    "    # Initialization step\n",
    "    for i, tag in enumerate(tags):\n",
    "        viterbi[i, 0] = initial_prob.get(tag, 0) * emission_prob[tag].get(sentence[0], 1e-6)\n",
    "        backpointer[i, 0] = 0\n",
    "    \n",
    "    # Recursion step\n",
    "    for t in range(1, n):\n",
    "        for i, tag in enumerate(tags):\n",
    "            max_prob = 0\n",
    "            best_tag = 0\n",
    "            for j, prev_tag in enumerate(tags):\n",
    "                prob = viterbi[j, t-1] * transition_prob[prev_tag].get(tag, 1e-6) * emission_prob[tag].get(sentence[t], 1e-6)\n",
    "                if prob > max_prob:\n",
    "                    max_prob = prob\n",
    "                    best_tag = j\n",
    "            viterbi[i, t] = max_prob\n",
    "            backpointer[i, t] = best_tag\n",
    "    \n",
    "    # Termination step\n",
    "    best_path_prob = max(viterbi[:, n-1])\n",
    "    best_path_pointer = np.argmax(viterbi[:, n-1])\n",
    "    \n",
    "    # Path backtracking\n",
    "    best_path = [0] * n\n",
    "    best_path[n-1] = best_path_pointer\n",
    "    for t in range(n-2, -1, -1):\n",
    "        best_path[t] = backpointer[best_path[t+1], t+1]\n",
    "    \n",
    "    best_tags = [tags[i] for i in best_path]\n",
    "    return best_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b727633-d6ed-4001-8302-051d0172d11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8875\n"
     ]
    }
   ],
   "source": [
    "def evaluate(test_data, tags, initial_prob, transition_prob, emission_prob):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for sentence in test_data:\n",
    "        words = [word for word, tag in sentence]\n",
    "        true_tags = [tag for word, tag in sentence]\n",
    "        predicted_tags = viterbi(words, tags, initial_prob, transition_prob, emission_prob)\n",
    "\n",
    "        correct += sum(p == t for p, t in zip(predicted_tags, true_tags))\n",
    "        total += len(true_tags)\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "accuracy = evaluate(test_data, tags, initial_prob, transition_prob, emission_prob)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1667f62-3f17-475b-ae05-3db9ceb7df29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRON'), ('want', 'VERB'), ('to', 'PRT'), ('eat', 'VERB'), ('biryani', 'DET'), ('today', 'NOUN')]\n"
     ]
    }
   ],
   "source": [
    "def tag_sentence(sentence, tags, initial_prob, transition_prob, emission_prob):\n",
    "    words = sentence.split()\n",
    "    tagged_sentence = viterbi(words, tags, initial_prob, transition_prob, emission_prob)\n",
    "    return list(zip(words, tagged_sentence))\n",
    "\n",
    "# Example sentence\n",
    "sentence = \"I want to eat biryani today\"\n",
    "tagged_sentence = tag_sentence(sentence, tags, initial_prob, transition_prob, emission_prob)\n",
    "print(tagged_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fafc1c4-d334-4130-9cf4-4c73e952d7b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa904374-94cd-43ad-ab44-16233e1b1b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b52a0b-8ba6-429a-9c75-89ea1601e2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9af5ee48-5099-46c8-9964-01f02f84a5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trigram_hmm_parameters(train_data):\n",
    "    tag_counts = Counter()\n",
    "    word_tag_counts = defaultdict(Counter)\n",
    "    transition_counts = defaultdict(Counter)\n",
    "    trigram_counts = Counter()\n",
    "\n",
    "    for sentence in train_data:\n",
    "        prev_tag1 = '<s>'\n",
    "        prev_tag2 = '<s>'\n",
    "        for word, tag in sentence:\n",
    "            tag_counts[tag] += 1\n",
    "            word_tag_counts[word][tag] += 1\n",
    "            transition_counts[(prev_tag1, prev_tag2)][tag] += 1\n",
    "            trigram_counts[(prev_tag1, prev_tag2)] += 1\n",
    "            prev_tag1, prev_tag2 = prev_tag2, tag\n",
    "        transition_counts[(prev_tag1, prev_tag2)]['</s>'] += 1\n",
    "        trigram_counts[(prev_tag1, prev_tag2)] += 1\n",
    "\n",
    "    tags = list(tag_counts.keys())\n",
    "    words = list(word_tag_counts.keys())\n",
    "    \n",
    "    # Compute initial probabilities with Laplace smoothing\n",
    "    initial_prob = {tag: (transition_counts[('<s>', '<s>')][tag] + 1) / (sum(transition_counts[('<s>', '<s>')].values()) + len(tags)) for tag in tags}\n",
    "    \n",
    "    # Compute transition probabilities with Laplace smoothing\n",
    "    transition_prob = {\n",
    "        (tag1, tag2): {tag: (transition_counts[(tag1, tag2)][tag] + 1) / (trigram_counts[(tag1, tag2)] + len(tags) + 1) for tag in tags + ['</s>']}\n",
    "        for tag1 in tags + ['<s>'] for tag2 in tags + ['<s>']\n",
    "    }\n",
    "    \n",
    "    # Compute emission probabilities with Laplace smoothing\n",
    "    emission_prob = {\n",
    "        tag: {word: (word_tag_counts[word][tag] + 1) / (tag_counts[tag] + len(words)) for word in words}\n",
    "        for tag in tags\n",
    "    }\n",
    "    \n",
    "    return tags, words, initial_prob, transition_prob, emission_prob\n",
    "\n",
    "tags, words, initial_prob, transition_prob, emission_prob = create_trigram_hmm_parameters(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a535209-6890-4798-8f34-528910e0bef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_trigram(sentence, tags, initial_prob, transition_prob, emission_prob):\n",
    "    n = len(sentence)\n",
    "    m = len(tags)\n",
    "    viterbi = np.zeros((m, m, n))\n",
    "    backpointer1 = np.zeros((m, m, n), dtype=int)\n",
    "    backpointer2 = np.zeros((m, m, n), dtype=int)\n",
    "    \n",
    "    # Initialization step\n",
    "    for i, tag1 in enumerate(tags):\n",
    "        for j, tag2 in enumerate(tags):\n",
    "            if n > 1:\n",
    "                viterbi[i, j, 0] = initial_prob.get(tag1, 1e-6) * initial_prob.get(tag2, 1e-6) * emission_prob[tag2].get(sentence[0], 1e-6) * emission_prob[tag2].get(sentence[1], 1e-6)\n",
    "            else:\n",
    "                viterbi[i, j, 0] = initial_prob.get(tag1, 1e-6) * emission_prob[tag1].get(sentence[0], 1e-6)\n",
    "            backpointer1[i, j, 0] = 0\n",
    "            backpointer2[i, j, 0] = 0\n",
    "    \n",
    "    # Recursion step\n",
    "    for t in range(2, n):\n",
    "        for i, tag1 in enumerate(tags):\n",
    "            for j, tag2 in enumerate(tags):\n",
    "                max_prob = 0\n",
    "                best_tag1 = 0\n",
    "                best_tag2 = 0\n",
    "                for k, prev_tag1 in enumerate(tags):\n",
    "                    for l, prev_tag2 in enumerate(tags):\n",
    "                        prob = viterbi[k, l, t-2] * transition_prob.get((prev_tag1, prev_tag2), {}).get(tag1, 1e-6) * transition_prob.get((prev_tag2, tag1), {}).get(tag2, 1e-6) * emission_prob[tag2].get(sentence[t], 1e-6)\n",
    "                        if prob > max_prob:\n",
    "                            max_prob = prob\n",
    "                            best_tag1 = k\n",
    "                            best_tag2 = l\n",
    "                viterbi[i, j, t] = max_prob\n",
    "                backpointer1[i, j, t] = best_tag1\n",
    "                backpointer2[i, j, t] = best_tag2\n",
    "    \n",
    "    # Termination step\n",
    "    best_path_prob = 0\n",
    "    best_path_pointer = (0, 0)\n",
    "    for i, tag1 in enumerate(tags):\n",
    "        for j, tag2 in enumerate(tags):\n",
    "            if viterbi[i, j, n-1] > best_path_prob:\n",
    "                best_path_prob = viterbi[i, j, n-1]\n",
    "                best_path_pointer = (i, j)\n",
    "    \n",
    "    # Path backtracking\n",
    "    best_path = [0] * n\n",
    "    best_path[n-1] = best_path_pointer[1]\n",
    "    best_path[n-2] = best_path_pointer[0]\n",
    "    for t in range(n-3, -1, -1):\n",
    "        best_path[t] = backpointer2[best_path[t+1], best_path[t+2], t+2]\n",
    "        best_path[t-1] = backpointer1[best_path[t+1], best_path[t+2], t+2]\n",
    "    \n",
    "    best_tags = [tags[i] for i in best_path]\n",
    "    return best_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d64060c-33e1-4243-adb9-bdd907c2130a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5272\n"
     ]
    }
   ],
   "source": [
    "def evaluate_trigram(test_data, tags, initial_prob, transition_prob, emission_prob):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for sentence in test_data:\n",
    "        words = [word for word, tag in sentence]\n",
    "        true_tags = [tag for word, tag in sentence]\n",
    "        predicted_tags = viterbi_trigram(words, tags, initial_prob, transition_prob, emission_prob)\n",
    "\n",
    "        correct += sum(p == t for p, t in zip(predicted_tags, true_tags))\n",
    "        total += len(true_tags)\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "accuracy = evaluate_trigram(test_data, tags, initial_prob, transition_prob, emission_prob)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccecaaf8-bad1-4f16-ba89-cf3c7ad917cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc61926-0d0d-4d24-aa02-5feb3f8f320d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0a1231-c7d0-4b52-9f79-38d268957edc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab1cb1b-b158-41af-a01d-422981f97ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3b0fb1-0f4b-4079-b7ec-7e78e3b4b3da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071bb07d-2909-4b09-bad7-c65e1a163bee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1fd9ad-5e32-43b1-8384-73dbc6ab2e17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8305e5-048f-4ea6-833b-f08a93aae22d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
